{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79f7f601-43c8-487e-825a-a18569af0d29",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Youtube comments analysis\n",
    "\n",
    "In this notebook, we have a dataset of user comments for youtube videos related to animals or pets. We will attempt to identify cat or dog owners based on these comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1c6b223-523a-48f3-a3d9-82512020ee80",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter will be restarted.\nCollecting googledrivedownloader==0.4\n  Using cached googledrivedownloader-0.4-py2.py3-none-any.whl (3.9 kB)\nInstalling collected packages: googledrivedownloader\nSuccessfully installed googledrivedownloader-0.4\nPython interpreter will be restarted.\n"
     ]
    }
   ],
   "source": [
    "#pip install googledrivedownloader==0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d30803b-2b9e-4710-901b-873736b9bf10",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter will be restarted.\nCollecting wordcloud\n  Downloading wordcloud-1.9.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (513 kB)\nRequirement already satisfied: matplotlib in /databricks/python3/lib/python3.9/site-packages (from wordcloud) (3.5.1)\nRequirement already satisfied: pillow in /databricks/python3/lib/python3.9/site-packages (from wordcloud) (9.0.1)\nRequirement already satisfied: numpy>=1.6.1 in /databricks/python3/lib/python3.9/site-packages (from wordcloud) (1.21.5)\nRequirement already satisfied: packaging>=20.0 in /databricks/python3/lib/python3.9/site-packages (from matplotlib->wordcloud) (21.3)\nRequirement already satisfied: python-dateutil>=2.7 in /databricks/python3/lib/python3.9/site-packages (from matplotlib->wordcloud) (2.8.2)\nRequirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.9/site-packages (from matplotlib->wordcloud) (4.25.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /databricks/python3/lib/python3.9/site-packages (from matplotlib->wordcloud) (1.3.2)\nRequirement already satisfied: pyparsing>=2.2.1 in /databricks/python3/lib/python3.9/site-packages (from matplotlib->wordcloud) (3.0.4)\nRequirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.9/site-packages (from matplotlib->wordcloud) (0.11.0)\nRequirement already satisfied: six>=1.5 in /databricks/python3/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\nInstalling collected packages: wordcloud\nSuccessfully installed wordcloud-1.9.3\nPython interpreter will be restarted.\n"
     ]
    }
   ],
   "source": [
    "#pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "012d7842-0a42-453e-8d86-9f94cd882eef",
     "showTitle": true,
     "title": "Download data"
    }
   },
   "outputs": [],
   "source": [
    "# link: https://drive.google.com/file/d/1o3DsS3jN_t2Mw3TsV0i7ySRmh9kyYi1a/view?usp=sharing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26df3af0-0bc7-418a-a1ea-6816061a8950",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 0. Data Exploration and Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f03d93da-f94a-4548-856d-daa3a8379539",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+-------------------------------------+\n|        creator_name|userid|                              comment|\n+--------------------+------+-------------------------------------+\n|        Doug The Pug|  87.0|                 I shared this to ...|\n|        Doug The Pug|  87.0|                   Super cute  üòÄüêïüê∂|\n|         bulletproof| 530.0|                 stop saying get e...|\n|       Meu Zool√≥gico| 670.0|                 Tenho uma jiboia ...|\n|              ojatro|1031.0|                 I wanna see what ...|\n|     Tingle Triggers|1212.0|                 Well shit now Im ...|\n|Hope For Paws - O...|1806.0|                 when I saw the en...|\n|Hope For Paws - O...|2036.0|                 Holy crap. That i...|\n|          Life Story|2637.0|Ê≠¶Âô®„ÅØ„ÇØ„Ç®„Çπ„Éà„ÅßË≤∞„Åà„Çã„Çì„Åò„ÇÉ„Å™„ÅÑ„Çì...|\n|       Brian Barczyk|2698.0|                 Call the teddy Larry|\n+--------------------+------+-------------------------------------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_clean=spark.read.csv(\"/FileStore/tables/animals_comments_csv.gz\",inferSchema=True,header=True)\n",
    "df_clean.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e156f764-0a50-4176-8e63-17656725ca67",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[3]: 1000000"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import rand \n",
    "\n",
    "df_clean.orderBy(rand(seed=0)).createOrReplaceTempView(\"table1\")\n",
    "df_clean = spark.sql(\"select * from table1 limit 1000000\")\n",
    "\n",
    "df_clean.count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a19e993-a440-4b8d-9120-3a5c8e3b3c57",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[4]: 999821"
     ]
    }
   ],
   "source": [
    "df_clean = df_clean.na.drop(subset=[\"comment\"])\n",
    "df_clean.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66614e0d-bb27-47af-bfb3-c64d2398584d",
     "showTitle": true,
     "title": "look at the data"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+---------+---------------------------------+\n|           creator_name|   userid|                          comment|\n+-----------------------+---------+---------------------------------+\n|         LightningLpsTV|2383838.0|             I dare Dakota to ...|\n|        Viktor Larkhill| 348139.0|               damn Im crying now|\n|        Einstein Parrot| 585165.0|             Einstein youre so...|\n|   REALITY TALK REVIEWS|1579903.0|             Ben is just a pup...|\n|       Brave Wilderness| 413490.0|             coyote i wanted t...|\n|            Info Marvel|1982636.0|             Quiero un funko p...|\n|         Obscure Domain|2508747.0|             This has never be...|\n|             The Fatman| 597566.0|             something to thin...|\n|Íº¨Î∂ÄÍ∏∞ÏïÑÎπ† My Pet Diary|2107492.0|Ïò§ÎäòÏùÄ ÏßÑÏßú ÏßëÏÇ¨ÎãòÏù¥ Î∂ÄÎüΩÍ≤å Îäê...|\n|              GoHerping|1467709.0|             Red eared sliders...|\n|          eMusic Talent|1853119.0|             OMG! El segundo n...|\n|     Taylor Nicole Dean|  63136.0|             I like to watch t...|\n|        Gohan The Husky|1339216.0|             for 300k go on a ...|\n|          Brian Barczyk|1955304.0|             I do it all the t...|\n|   REALITY TALK REVIEWS|2157552.0|             U can see why I s...|\n|          Connor OBrien|2361478.0|                         Love it!|\n|          Brian Barczyk|1387966.0|             Make your money B...|\n|    Keedes channel LIVE| 967687.0|                –î–∞ –∑–∞–±–µ—Ä–∏—Ç–µ —â–µ–Ω–∫–∞|\n|             Kamp Kenan|2000048.0|             Hello from Israel...|\n|       Brave Wilderness| 847354.0|             It sounds like a ...|\n+-----------------------+---------+---------------------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_clean.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08ae580e-abce-4ba6-9944-2b91e8dc9c42",
     "showTitle": true,
     "title": "Label the data"
    }
   },
   "outputs": [],
   "source": [
    "# find user with preference of dog and cat\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "df_clean = df_clean.withColumn(\"label\", \\\n",
    "                           (when(col(\"comment\").like(\"%my dog%\"), 1) \\\n",
    "                           .when(col(\"comment\").like(\"%I have a dog%\"), 1) \\\n",
    "                           .when(col(\"comment\").like(\"%my cat%\"), 1) \\\n",
    "                           .when(col(\"comment\").like(\"%I have a cat%\"), 1) \\\n",
    "                           .when(col(\"comment\").like(\"%my puppy%\"), 1) \\\n",
    "                           .when(col(\"comment\").like(\"%my pup%\"), 1) \\\n",
    "                           .when(col(\"comment\").like(\"%my kitty%\"), 1) \\\n",
    "                           .when(col(\"comment\").like(\"%my pussy%\"), 1) \\\n",
    "                           .otherwise(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da1ed3af-6c6f-4089-8ccc-1f4939b32041",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+---------+---------------------------------+-----+\n|           creator_name|   userid|                          comment|label|\n+-----------------------+---------+---------------------------------+-----+\n|         LightningLpsTV|2383838.0|             I dare Dakota to ...|    0|\n|        Viktor Larkhill| 348139.0|               damn Im crying now|    0|\n|        Einstein Parrot| 585165.0|             Einstein youre so...|    0|\n|   REALITY TALK REVIEWS|1579903.0|             Ben is just a pup...|    0|\n|       Brave Wilderness| 413490.0|             coyote i wanted t...|    0|\n|            Info Marvel|1982636.0|             Quiero un funko p...|    0|\n|         Obscure Domain|2508747.0|             This has never be...|    0|\n|             The Fatman| 597566.0|             something to thin...|    0|\n|Íº¨Î∂ÄÍ∏∞ÏïÑÎπ† My Pet Diary|2107492.0|Ïò§ÎäòÏùÄ ÏßÑÏßú ÏßëÏÇ¨ÎãòÏù¥ Î∂ÄÎüΩÍ≤å Îäê...|    0|\n|              GoHerping|1467709.0|             Red eared sliders...|    0|\n|          eMusic Talent|1853119.0|             OMG! El segundo n...|    0|\n|     Taylor Nicole Dean|  63136.0|             I like to watch t...|    0|\n|        Gohan The Husky|1339216.0|             for 300k go on a ...|    0|\n|          Brian Barczyk|1955304.0|             I do it all the t...|    0|\n|   REALITY TALK REVIEWS|2157552.0|             U can see why I s...|    0|\n|          Connor OBrien|2361478.0|                         Love it!|    0|\n|          Brian Barczyk|1387966.0|             Make your money B...|    0|\n|    Keedes channel LIVE| 967687.0|                –î–∞ –∑–∞–±–µ—Ä–∏—Ç–µ —â–µ–Ω–∫–∞|    0|\n|             Kamp Kenan|2000048.0|             Hello from Israel...|    0|\n|       Brave Wilderness| 847354.0|             It sounds like a ...|    0|\n+-----------------------+---------+---------------------------------+-----+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_clean.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ed6b1c0-d267-4a46-b4ba-abf1e85ef658",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 1. Data preprocessing and Build the classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7db7d748-cea0-4f04-a29c-05ba324c520a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer, Word2Vec\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# regular expression tokenizer\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"comment\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "word2Vec = Word2Vec(vectorSize=50, minCount=1, inputCol=\"words\", outputCol=\"wordVector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "edd5514f-8408-4555-a4fc-5ebc077a1b99",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "pipeline = Pipeline(stages=[regexTokenizer, word2Vec])\n",
    "\n",
    "# Fit the pipeline to training documents.\n",
    "pipelineFit = pipeline.fit(df_clean)\n",
    "dataset = pipelineFit.transform(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "519ad9e9-d95b-404a-a703-c5b63ef56c9e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+---------+---------------------------------+-----+--------------------+--------------------+\n|           creator_name|   userid|                          comment|label|               words|          wordVector|\n+-----------------------+---------+---------------------------------+-----+--------------------+--------------------+\n|         LightningLpsTV|2383838.0|             I dare Dakota to ...|    0|[i, dare, dakota,...|[-0.0084864338859...|\n|        Viktor Larkhill| 348139.0|               damn Im crying now|    0|[damn, im, crying...|[-0.0179006536491...|\n|        Einstein Parrot| 585165.0|             Einstein youre so...|    0|[einstein, youre,...|[-0.0763257555404...|\n|   REALITY TALK REVIEWS|1579903.0|             Ben is just a pup...|    0|[ben, is, just, a...|[-0.1381724602745...|\n|       Brave Wilderness| 413490.0|             coyote i wanted t...|    0|[coyote, i, wante...|[-0.0763060057150...|\n|            Info Marvel|1982636.0|             Quiero un funko p...|    0|[quiero, un, funk...|[0.25439684540033...|\n|         Obscure Domain|2508747.0|             This has never be...|    0|[this, has, never...|[-0.1287734081201...|\n|             The Fatman| 597566.0|             something to thin...|    0|[something, to, t...|[-0.1649090753868...|\n|Íº¨Î∂ÄÍ∏∞ÏïÑÎπ† My Pet Diary|2107492.0|Ïò§ÎäòÏùÄ ÏßÑÏßú ÏßëÏÇ¨ÎãòÏù¥ Î∂ÄÎüΩÍ≤å Îäê...|    0|                  []|          (50,[],[])|\n|              GoHerping|1467709.0|             Red eared sliders...|    0|[red, eared, slid...|[-0.0515516620256...|\n|          eMusic Talent|1853119.0|             OMG! El segundo n...|    0|[omg, el, segundo...|[0.23934797570109...|\n|     Taylor Nicole Dean|  63136.0|             I like to watch t...|    0|[i, like, to, wat...|[-0.0163299292325...|\n|        Gohan The Husky|1339216.0|             for 300k go on a ...|    0|[for, 300k, go, o...|[0.03062417677470...|\n|          Brian Barczyk|1955304.0|             I do it all the t...|    0|[i, do, it, all, ...|[-0.0737846706594...|\n|   REALITY TALK REVIEWS|2157552.0|             U can see why I s...|    0|[u, can, see, why...|[-0.0184104631965...|\n|          Connor OBrien|2361478.0|                         Love it!|    0|          [love, it]|[0.15159025043249...|\n|          Brian Barczyk|1387966.0|             Make your money B...|    0|[make, your, mone...|[0.08665094850584...|\n|    Keedes channel LIVE| 967687.0|                –î–∞ –∑–∞–±–µ—Ä–∏—Ç–µ —â–µ–Ω–∫–∞|    0|                  []|          (50,[],[])|\n|             Kamp Kenan|2000048.0|             Hello from Israel...|    0|[hello, from, isr...|[-0.0629221008081...|\n|       Brave Wilderness| 847354.0|             It sounds like a ...|    0|[it, sounds, like...|[-0.1286318272352...|\n+-----------------------+---------+---------------------------------+-----+--------------------+--------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "dataset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f9dfb80-d6c2-408b-a21c-2008b6c4775e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "(lable0_train,lable0_test)=dataset.filter(col('label')==1).randomSplit([0.7, 0.3],seed = 100)\n",
    "(lable1_train, lable1_ex)=dataset.filter(col('label')==0).randomSplit([0.005, 0.995],seed = 100)\n",
    "(lable1_test, lable1_ex2)=lable1_ex.randomSplit([0.002, 0.998],seed = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9d416bf-c8b5-4702-8fcd-2ea98ab205f4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "trainingData = lable0_train.union(lable1_train)\n",
    "testData=lable0_test.union(lable1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6662613d-0a13-4d16-b43e-9aebf08b636d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Count: 999821\nTraining Dataset Count: 9788\nTest Dataset Count: 4049\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Count: \" + str(dataset.count()))\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "072997be-3dff-4b5f-8cac-0411408ebaf7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 2. Models\n",
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e30776a-e1db-45ae-94b9-92724dc7de6f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+----------+\n|        creator_name|   userid|             comment|label|               words|          wordVector|       rawPrediction|         probability|prediction|\n+--------------------+---------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+----------+\n|                null|1265524.0|if i saw a snake ...|    1|[if, i, saw, a, s...|[-0.0768854211394...|[-0.6479574422907...|[0.34344997054044...|       1.0|\n|           278pikelk| 152729.0|I just told my do...|    1|[i, just, told, m...|[-0.1650808578695...|[-0.1937053818619...|[0.45172450873112...|       1.0|\n|2CAN.TV - Ripley ...| 231728.0|He acts like my d...|    1|[he, acts, like, ...|[-0.2551775995641...|[-1.1044695141026...|[0.24890337915506...|       1.0|\n|      Aarons Animals| 117349.0|I love cats I hav...|    1|[i, love, cats, i...|[-0.0641256729140...|[-0.5314423587878...|[0.37018054361900...|       1.0|\n|      Aarons Animals| 264843.0|Yeah my cat watch...|    1|[yeah, my, cat, w...|[-0.0370414492984...|[-0.3064709229196...|[0.42397637944974...|       1.0|\n|      Aarons Animals| 937383.0|This is like my c...|    1|[this, is, like, ...|[-0.0821391599825...|[0.34599662789509...|[0.58564643615183...|       0.0|\n|      Aarons Animals| 968778.0|Thats my life Mic...|    1|[thats, my, life,...|[-0.1289870857114...|[-0.5942457718242...|[0.35566127117510...|       1.0|\n|      Aarons Animals|1625385.0|my daughter watch...|    1|[my, daughter, wa...|[-0.0613354153931...|[-0.5840545613235...|[0.35800017374815...|       1.0|\n|      Aarons Animals|2270295.0|I quess my cat lo...|    1|[i, quess, my, ca...|[-0.1300688708433...|[-0.2566287156678...|[0.43619262440084...|       1.0|\n|  Alex Knappenberger| 430815.0|  my dog is the same|    1|[my, dog, is, the...|[-0.2623064458370...|[-1.2408781885421...|[0.22428316129712...|       1.0|\n+--------------------+---------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+----------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "\n",
    "lr = LogisticRegression(featuresCol=\"wordVector\",labelCol=\"label\" , maxIter=10, regParam=0.1, elasticNetParam=0.8)\n",
    "lrModel = lr.fit(trainingData)\n",
    "\n",
    "# Make predictions on test data.\n",
    "predictions = lrModel.transform(testData)\n",
    "predictions.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91a962c9-4b58-41b2-8f66-b8751e60a71b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n|                 FPR|                 TPR|\n+--------------------+--------------------+\n|                 0.0|                 0.0|\n|6.127450980392157E-4|0.001635322976287817|\n|8.169934640522876E-4|0.003475061324611611|\n|0.001429738562091...|0.004701553556827474|\n|0.001633986928104...|0.006745707277187245|\n|0.001838235294117647|0.008381030253475062|\n|0.002246732026143...|0.009811937857726901|\n|0.002450980392156...|0.011447260834014717|\n|0.002450980392156...|0.013286999182338511|\n|0.002450980392156...|0.015126737530662305|\n|0.002655228758169...|  0.0169664758789861|\n|0.003063725490196...| 0.01839738348323794|\n|0.003267973856209...|0.020032706459525755|\n|0.003267973856209...| 0.02187244480784955|\n|0.003676470588235294| 0.02391659852820932|\n|0.004084967320261438|0.025347506132461162|\n| 0.00428921568627451| 0.02698282910874898|\n| 0.00428921568627451|0.028822567457072772|\n| 0.00428921568627451|0.030662305805396566|\n|0.004493464052287581|0.032297628781684386|\n+--------------------+--------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "trainingSummary = lrModel.summary\n",
    "\n",
    "\n",
    "# Obtain the receiver-operating characteristic as a dataframe and areaUnderROC.\n",
    "trainingSummary.roc.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "612dbd01-2885-47fd-ad15-5948e54ed491",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "areaUnderROC: 0.8925807240312325\n"
     ]
    }
   ],
   "source": [
    "print(\"areaUnderROC: \" + str(trainingSummary.areaUnderROC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b8d4c11-addc-4615-860c-7e49c6fc1879",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction result summary for Logistic Regression Model:  \nTrue Positives: 1878\nFalse Positives: 494\nTrue Negatives: 1459\nFalse Negatives: 218\nTest Accuracy: 0.824154112126451\nTest Precision: 0.7917369308600337\nTest Recall: 0.8959923664122137\nTest AUC of ROC: 0.8911314751625018\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "\n",
    "def get_evaluation_result(predictions):\n",
    "  evaluator = BinaryClassificationEvaluator(\n",
    "      labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "  AUC = evaluator.evaluate(predictions)\n",
    "\n",
    "  TP = predictions[(predictions[\"label\"] == 1) & (predictions[\"prediction\"] == 1.0)].count()\n",
    "  FP = predictions[(predictions[\"label\"] == 0) & (predictions[\"prediction\"] == 1.0)].count()\n",
    "  TN = predictions[(predictions[\"label\"] == 0) & (predictions[\"prediction\"] == 0.0)].count()\n",
    "  FN = predictions[(predictions[\"label\"] == 1) & (predictions[\"prediction\"] == 0.0)].count()\n",
    "\n",
    "  accuracy = (TP + TN)*1.0 / (TP + FP + TN + FN)\n",
    "  precision = TP*1.0 / (TP + FP)\n",
    "  recall = TP*1.0 / (TP + FN)\n",
    "\n",
    "\n",
    "  print (\"True Positives:\", TP)\n",
    "  print (\"False Positives:\", FP)\n",
    "  print (\"True Negatives:\", TN)\n",
    "  print (\"False Negatives:\", FN)\n",
    "  print (\"Test Accuracy:\", accuracy)\n",
    "  print (\"Test Precision:\", precision)\n",
    "  print (\"Test Recall:\", recall)\n",
    "  print (\"Test AUC of ROC:\", AUC)\n",
    "\n",
    "print(\"Prediction result summary for Logistic Regression Model:  \")\n",
    "get_evaluation_result(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90b82331-a0f3-45a2-94a8-f541b16855f0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Parameter Tuning and K-fold cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44d9dc56-544a-447b-87a1-191c362c5dba",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8da60d48-eea2-4756-a6fa-2915e1bf22e2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+----------+\n|        creator_name|   userid|             comment|label|               words|          wordVector|       rawPrediction|         probability|prediction|\n+--------------------+---------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+----------+\n|                null|1265524.0|if i saw a snake ...|    1|[if, i, saw, a, s...|[-0.0768854211394...|[5.05177563308591...|[0.33678504220572...|       1.0|\n|           278pikelk| 152729.0|I just told my do...|    1|[i, just, told, m...|[-0.1650808578695...|[2.59045922781202...|[0.17269728185413...|       1.0|\n|2CAN.TV - Ripley ...| 231728.0|He acts like my d...|    1|[he, acts, like, ...|[-0.2551775995641...|[3.32790614663259...|[0.22186040977550...|       1.0|\n|      Aarons Animals| 117349.0|I love cats I hav...|    1|[i, love, cats, i...|[-0.0641256729140...|[3.89586535558406...|[0.25972435703893...|       1.0|\n|      Aarons Animals| 264843.0|Yeah my cat watch...|    1|[yeah, my, cat, w...|[-0.0370414492984...|[4.30179102021200...|[0.28678606801413...|       1.0|\n|      Aarons Animals| 937383.0|This is like my c...|    1|[this, is, like, ...|[-0.0821391599825...|[5.64518917387787...|[0.37634594492519...|       1.0|\n|      Aarons Animals| 968778.0|Thats my life Mic...|    1|[thats, my, life,...|[-0.1289870857114...|[2.59045922781202...|[0.17269728185413...|       1.0|\n|      Aarons Animals|1625385.0|my daughter watch...|    1|[my, daughter, wa...|[-0.0613354153931...|[3.00334929210710...|[0.20022328614047...|       1.0|\n|      Aarons Animals|2270295.0|I quess my cat lo...|    1|[i, quess, my, ca...|[-0.1300688708433...|[2.59045922781202...|[0.17269728185413...|       1.0|\n|  Alex Knappenberger| 430815.0|  my dog is the same|    1|[my, dog, is, the...|[-0.2623064458370...|[2.79482012632128...|[0.18632134175475...|       1.0|\n+--------------------+---------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+----------+\nonly showing top 10 rows\n\nPrediction result summary for Random Forest Model:  \nTrue Positives: 1846\nFalse Positives: 342\nTrue Negatives: 1611\nFalse Negatives: 250\nTest Accuracy: 0.8537910595208693\nTest Precision: 0.8436928702010968\nTest Recall: 0.8807251908396947\nTest AUC of ROC: 0.9294812883291727\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# Train a RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"wordVector\", numTrees=15)\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = rf.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.show(10)\n",
    "\n",
    "print(\"Prediction result summary for Random Forest Model:  \")\n",
    "get_evaluation_result(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f86cfb98-64b5-4254-875f-c4606c8daa0c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 3. Classify All The Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54ef9b43-00e9-40c5-995b-facfb8b82817",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 992833 users whose attribute is unclear.\n+-----------------------+---------+---------------------------------+-----+--------------------+--------------------+--------------------+--------------------+----------+\n|           creator_name|   userid|                          comment|label|               words|          wordVector|       rawPrediction|         probability|prediction|\n+-----------------------+---------+---------------------------------+-----+--------------------+--------------------+--------------------+--------------------+----------+\n|         LightningLpsTV|2383838.0|             I dare Dakota to ...|    0|[i, dare, dakota,...|[-0.0084864338859...|[9.73575870205387...|[0.64905058013692...|       0.0|\n|        Viktor Larkhill| 348139.0|               damn Im crying now|    0|[damn, im, crying...|[-0.0179006536491...|[10.4466641211398...|[0.69644427474265...|       0.0|\n|        Einstein Parrot| 585165.0|             Einstein youre so...|    0|[einstein, youre,...|[-0.0763257555404...|[12.9514633968717...|[0.86343089312478...|       0.0|\n|   REALITY TALK REVIEWS|1579903.0|             Ben is just a pup...|    0|[ben, is, just, a...|[-0.1381724602745...|[9.70989883758947...|[0.64732658917263...|       0.0|\n|       Brave Wilderness| 413490.0|             coyote i wanted t...|    0|[coyote, i, wante...|[-0.0763060057150...|[8.45995164353216...|[0.56399677623547...|       0.0|\n|            Info Marvel|1982636.0|             Quiero un funko p...|    0|[quiero, un, funk...|[0.25439684540033...|[14.1515228732773...|[0.94343485821848...|       0.0|\n|         Obscure Domain|2508747.0|             This has never be...|    0|[this, has, never...|[-0.1287734081201...|[3.62545134696136...|[0.24169675646409...|       1.0|\n|             The Fatman| 597566.0|             something to thin...|    0|[something, to, t...|[-0.1649090753868...|[9.19336443334065...|[0.61289096222271...|       0.0|\n|Íº¨Î∂ÄÍ∏∞ÏïÑÎπ† My Pet Diary|2107492.0|Ïò§ÎäòÏùÄ ÏßÑÏßú ÏßëÏÇ¨ÎãòÏù¥ Î∂ÄÎüΩÍ≤å Îäê...|    0|                  []|          (50,[],[])|[14.2763428498945...|[0.95175618999296...|       0.0|\n|              GoHerping|1467709.0|             Red eared sliders...|    0|[red, eared, slid...|[-0.0515516620256...|[4.15528007795191...|[0.27701867186346...|       1.0|\n+-----------------------+---------+---------------------------------+-----+--------------------+--------------------+--------------------+--------------------+----------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "# get dataset for prediction (note to exclude people we already know the label)\n",
    "df_unknown = dataset.filter(F.col('label') == False)\n",
    "df_unknown = df_unknown.withColumn('label',df_unknown.label.cast('integer'))\n",
    "print(\"There are {} users whose attribute is unclear.\".format(df_unknown.count()))\n",
    "pred_all = model.transform(df_unknown)\n",
    "pred_all.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4bf63290-5bc4-47a1-9ef0-6a4ecf283d6b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of the users who are cat/dog owners (ML estimate):  1.251\n"
     ]
    }
   ],
   "source": [
    "#number of total user\n",
    "total_user = dataset.select('userid').distinct().count()\n",
    "#number of labeled owner\n",
    "owner_labeled = dataset.select('userid').distinct().count() \n",
    "#number of owner predicted\n",
    "owner_pred = pred_all.filter(F.col('prediction') == 1.0).count()\n",
    "\n",
    "fraction = (owner_labeled+owner_pred)/total_user\n",
    "print('Fraction of the users who are cat/dog owners (ML estimate): ', round(fraction,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6e106e1-1f2a-4a8e-b711-a29633953fa6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 4. Get insigts of Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dabea32f-80e7-4f43-ba60-c5aa22c92434",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n|               words|            filtered|\n+--------------------+--------------------+\n|[i, dare, dakota,...|[dare, dakota, pr...|\n+--------------------+--------------------+\nonly showing top 1 row\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover\n",
    "\n",
    "df_all_owner = dataset.select('words').union(pred_all.filter(F.col('prediction') == 1.0).select('words'))\n",
    "\n",
    "stopwords_custom = ['im', 'get', 'got', 'one', 'hes', 'shes', 'dog', 'dogs', 'cats', 'cat', 'kitty', 'much', 'really', 'love','like','dont','know','want','thin',\\\n",
    "                    'see','also','never','go','ive']\n",
    "\n",
    "remover1 = StopWordsRemover(inputCol=\"raw\", outputCol=\"filtered\")\n",
    "core = remover1.getStopWords()\n",
    "core = core + stopwords_custom\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\",stopWords=core)\n",
    "df_all_owner = remover.transform(df_all_owner)\n",
    "\n",
    "wc = df_all_owner.select('filtered').rdd.flatMap(lambda a: a.filtered).countByValue()\n",
    "\n",
    "df_all_owner.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5d0dad0-dfc9-4d1c-a78e-6136f44c49bb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[22]: [('video', 64795),\n ('good', 51323),\n ('people', 46221),\n ('cute', 40752),\n ('great', 39885),\n ('videos', 38589),\n ('u', 38494),\n ('think', 38333),\n ('animals', 35791),\n ('time', 34370),\n ('lol', 33660),\n ('coyote', 30644),\n ('make', 30294),\n ('thank', 29146),\n ('3', 28040),\n ('little', 27669),\n ('keep', 26591),\n ('day', 25574),\n ('even', 25515),\n ('happy', 25021),\n ('hope', 24746),\n ('always', 24520),\n ('please', 24407),\n ('n', 23912),\n ('channel', 23770),\n ('going', 23663),\n ('thats', 23656),\n ('cant', 23515),\n ('2', 23429),\n ('back', 23101),\n ('well', 22829),\n ('need', 22731),\n ('new', 22674),\n ('nice', 22297),\n ('first', 22041),\n ('beautiful', 21854),\n ('looks', 21850),\n ('way', 21832),\n ('look', 21684),\n ('thanks', 21493),\n ('name', 21248),\n ('m', 21236),\n ('take', 21096),\n ('best', 20947),\n ('amazing', 20822),\n ('ever', 20819),\n ('awesome', 20797),\n ('life', 20778),\n ('guys', 20011),\n ('man', 19846),\n ('1', 19754),\n ('still', 19425),\n ('thing', 18912),\n ('work', 18617),\n ('watch', 18484),\n ('help', 18483),\n ('say', 18394),\n ('god', 18361),\n ('give', 17922),\n ('watching', 17903),\n ('big', 17790),\n ('better', 17584),\n ('animal', 17440),\n ('fish', 17335),\n ('y', 17333),\n ('snake', 17300),\n ('us', 17169),\n ('put', 17112),\n ('de', 17076),\n ('live', 17013),\n ('bad', 16995),\n ('omg', 16848),\n ('many', 16785),\n ('right', 16633),\n ('old', 16510),\n ('que', 16490),\n ('horse', 16372),\n ('feel', 16152),\n ('cool', 16076),\n ('poor', 15953),\n ('something', 15947),\n ('baby', 15554),\n ('every', 15477),\n ('didnt', 15323),\n ('oh', 15228),\n ('getting', 15194),\n ('care', 14910),\n ('lot', 14545),\n ('made', 14480),\n ('c', 14365),\n ('years', 14289),\n ('youre', 14287),\n ('come', 14242),\n ('let', 13982),\n ('said', 13632),\n ('snakes', 13478),\n ('find', 13405),\n ('hey', 13304),\n ('use', 13285),\n ('things', 13278),\n ('two', 13130),\n ('home', 13087),\n ('around', 12936),\n ('hi', 12712),\n ('tank', 12672),\n ('brian', 12608),\n ('sure', 12492),\n ('d', 12484),\n ('wow', 12409),\n ('guy', 12372),\n ('eat', 12290),\n ('wish', 12245),\n ('pet', 12104),\n ('show', 12092),\n ('o', 12085),\n ('long', 11896),\n ('food', 11727),\n ('thought', 11663),\n ('family', 11659),\n ('away', 11596),\n ('el', 11595),\n ('doesnt', 11513),\n ('sorry', 11413),\n ('someone', 11291),\n ('try', 11286),\n ('sad', 11262),\n ('another', 11249),\n ('black', 11232),\n ('water', 11229),\n ('4', 11102),\n ('mom', 11033),\n ('year', 11007),\n ('seen', 10967),\n ('la', 10866),\n ('world', 10854),\n ('5', 10666),\n ('next', 10520),\n ('heart', 10512),\n ('makes', 10424),\n ('actually', 10396),\n ('looking', 10298),\n ('youtube', 10287),\n ('sweet', 10279),\n ('job', 10232),\n ('maybe', 10158),\n ('bit', 10113),\n ('ok', 10108),\n ('tell', 10059),\n ('house', 10055),\n ('pretty', 10050),\n ('adorable', 10019),\n ('stop', 10010),\n ('found', 9850),\n ('since', 9847),\n ('saw', 9818),\n ('girl', 9795),\n ('v', 9735),\n ('person', 9707),\n ('kind', 9627),\n ('hard', 9534),\n ('xd', 9483),\n ('glad', 9385),\n ('though', 9350),\n ('anyone', 9161),\n ('face', 9134),\n ('favorite', 9080),\n ('hate', 9066),\n ('ur', 9020),\n ('bless', 8934),\n ('10', 8883),\n ('friend', 8859),\n ('l', 8844),\n ('funny', 8809),\n ('trying', 8782),\n ('last', 8755),\n ('gets', 8729),\n ('id', 8728),\n ('mean', 8648),\n ('real', 8644),\n ('wait', 8638),\n ('used', 8600),\n ('horses', 8564),\n ('yes', 8548),\n ('ng', 8344),\n ('anything', 8282),\n ('everything', 8261),\n ('stuff', 8224),\n ('done', 8190),\n ('gonna', 7963),\n ('loved', 7917),\n ('everyone', 7909),\n ('wanted', 7906),\n ('nh', 7789),\n ('probably', 7785),\n ('en', 7714),\n ('r', 7698),\n ('else', 7689),\n ('may', 7634),\n ('fun', 7628),\n ('theyre', 7596),\n ('ill', 7537),\n ('puppy', 7405),\n ('kill', 7295),\n ('place', 7275),\n ('max', 7248),\n ('6', 7231),\n ('went', 7216),\n ('kitten', 7143),\n ('part', 7099),\n ('white', 7058),\n ('small', 7036),\n ('pets', 7012),\n ('end', 7004),\n ('birthday', 6965),\n ('b', 6961),\n ('ago', 6955),\n ('eyes', 6955),\n ('might', 6955),\n ('super', 6925),\n ('wrong', 6921),\n ('hurt', 6893),\n ('died', 6842),\n ('without', 6825),\n ('buy', 6823),\n ('p', 6814),\n ('soon', 6790),\n ('making', 6782),\n ('es', 6714),\n ('different', 6707),\n ('human', 6680),\n ('bite', 6665),\n ('boy', 6652),\n ('call', 6650),\n ('today', 6609),\n ('almost', 6598),\n ('start', 6580),\n ('money', 6576),\n ('needs', 6538),\n ('cause', 6530),\n ('days', 6512),\n ('play', 6502),\n ('head', 6468),\n ('0', 6436),\n ('fucking', 6431),\n ('believe', 6429),\n ('times', 6420),\n ('enough', 6403),\n ('wild', 6399),\n ('stay', 6383),\n ('must', 6378),\n ('hell', 6371),\n ('shit', 6362),\n ('comment', 6342),\n ('feed', 6340),\n ('seeing', 6337),\n ('die', 6312),\n ('boo', 6303),\n ('wont', 6302),\n ('wonderful', 6298),\n ('nothing', 6236),\n ('brave', 6231),\n ('already', 6226),\n ('started', 6188),\n ('bird', 6181),\n ('yo', 6160),\n ('ball', 6144),\n ('dad', 6040),\n ('vid', 6022),\n ('gohan', 6022),\n ('came', 6022),\n ('vet', 6009),\n ('vids', 5975),\n ('dude', 5962),\n ('ya', 5951),\n ('friends', 5942),\n ('kids', 5940),\n ('able', 5926),\n ('called', 5884),\n ('whole', 5875),\n ('isnt', 5825),\n ('understand', 5824),\n ('crazy', 5809),\n ('loves', 5749),\n ('saying', 5742),\n ('save', 5669),\n ('7', 5650),\n ('fuck', 5650),\n ('anh', 5643),\n ('un', 5640),\n ('kittens', 5636),\n ('turtle', 5636),\n ('scared', 5595),\n ('blue', 5591),\n ('los', 5566),\n ('pain', 5566),\n ('babies', 5499),\n ('hand', 5491),\n ('whats', 5467),\n ('sharing', 5413),\n ('cry', 5393),\n ('win', 5386),\n ('breed', 5368),\n ('cage', 5367),\n ('leave', 5365),\n ('red', 5348),\n ('se', 5332),\n ('humans', 5306),\n ('hear', 5298),\n ('left', 5284),\n ('theres', 5272),\n ('wanna', 5261),\n ('took', 5257),\n ('happened', 5255),\n ('haha', 5240),\n ('idea', 5218),\n ('least', 5199),\n ('8', 5191),\n ('owner', 5182),\n ('reason', 5169),\n ('question', 5160),\n ('yet', 5154),\n ('miss', 5142),\n ('eating', 5141),\n ('stung', 5140),\n ('agree', 5124),\n ('ones', 5122),\n ('lost', 5115),\n ('seems', 5115),\n ('dead', 5090),\n ('enjoy', 5079),\n ('e', 5077),\n ('monkey', 5068),\n ('school', 5049),\n ('remember', 5047),\n ('definitely', 5033),\n ('damn', 4989),\n ('brother', 4984),\n ('stupid', 4980),\n ('months', 4977),\n ('vlog', 4971),\n ('week', 4961),\n ('learn', 4953),\n ('watched', 4948),\n ('run', 4891),\n ('okay', 4874),\n ('k', 4850),\n ('room', 4820),\n ('wouldnt', 4813),\n ('book', 4806),\n ('coming', 4796),\n ('looked', 4746),\n ('lo', 4713),\n ('peterson', 4694),\n ('camera', 4664),\n ('talk', 4653),\n ('mine', 4635),\n ('sick', 4606),\n ('rescue', 4582),\n ('ch', 4578),\n ('read', 4564),\n ('wants', 4557),\n ('mark', 4534),\n ('full', 4517),\n ('thinking', 4511),\n ('con', 4507),\n ('together', 4506),\n ('safe', 4498),\n ('night', 4497),\n ('far', 4492),\n ('hit', 4473),\n ('cheese', 4470),\n ('com', 4464),\n ('husky', 4464),\n ('mind', 4450),\n ('yeah', 4421),\n ('free', 4405),\n ('python', 4394),\n ('huge', 4386),\n ('tried', 4384),\n ('th', 4380),\n ('says', 4380),\n ('crying', 4374),\n ('taking', 4362),\n ('true', 4360),\n ('absolutely', 4356),\n ('spider', 4342),\n ('aww', 4338),\n ('plz', 4333),\n ('pack', 4331),\n ('congrats', 4322),\n ('loving', 4321),\n ('sometimes', 4309),\n ('guess', 4300),\n ('por', 4298),\n ('side', 4297),\n ('sounds', 4288),\n ('song', 4288),\n ('em', 4287),\n ('likes', 4281),\n ('fan', 4278),\n ('music', 4262),\n ('second', 4250),\n ('story', 4248),\n ('h', 4240),\n ('named', 4228),\n ('wonder', 4219),\n ('20', 4218),\n ('luck', 4214),\n ('goes', 4213),\n ('parents', 4209),\n ('x', 4200),\n ('especially', 4196),\n ('si', 4176),\n ('gave', 4166),\n ('wasnt', 4163),\n ('close', 4156),\n ('female', 4156),\n ('male', 4134),\n ('couldnt', 4119),\n ('hair', 4101),\n ('check', 4074),\n ('hamster', 4072),\n ('9', 4071),\n ('bro', 4069),\n ('high', 4056),\n ('son', 4034),\n ('heard', 4024),\n ('mother', 3994),\n ('ask', 3987),\n ('told', 3978),\n ('living', 3975),\n ('talking', 3972),\n ('top', 3972),\n ('quiero', 3944),\n ('interesting', 3920),\n ('happen', 3919),\n ('others', 3881),\n ('robin', 3878),\n ('adopt', 3868),\n ('finally', 3860),\n ('type', 3858),\n ('point', 3858),\n ('knew', 3849),\n ('outside', 3836),\n ('morning', 3818),\n ('g', 3818),\n ('hello', 3813),\n ('grow', 3809),\n ('problem', 3806),\n ('kid', 3781),\n ('couple', 3776),\n ('taylor', 3767),\n ('puppies', 3764),\n ('ass', 3752),\n ('sound', 3728),\n ('fine', 3725),\n ('bring', 3709),\n ('using', 3703),\n ('lucky', 3701),\n ('comments', 3700),\n ('turtles', 3695),\n ('lives', 3687),\n ('cut', 3683),\n ('christmas', 3677),\n ('half', 3676),\n ('https', 3672),\n ('btw', 3668),\n ('instead', 3663),\n ('catch', 3659),\n ('comes', 3653),\n ('kinda', 3634),\n ('change', 3622),\n ('literally', 3618),\n ('car', 3589),\n ('12', 3581),\n ('reptiles', 3577),\n ('either', 3573),\n ('young', 3568),\n ('eye', 3567),\n ('lovely', 3558),\n ('episode', 3555),\n ('perfect', 3528),\n ('wondering', 3506),\n ('box', 3488),\n ('respect', 3477),\n ('early', 3472),\n ('11', 3460),\n ('awww', 3457),\n ('excited', 3451),\n ('mr', 3445),\n ('later', 3442),\n ('walk', 3440),\n ('100', 3434),\n ('month', 3428),\n ('three', 3427),\n ('move', 3420),\n ('weeks', 3417),\n ('store', 3411),\n ('alone', 3344),\n ('totally', 3340),\n ('arent', 3339),\n ('rest', 3338),\n ('deserve', 3328),\n ('mi', 3314),\n ('lots', 3302),\n ('wilderness', 3296),\n ('seem', 3295),\n ('set', 3290),\n ('pick', 3287),\n ('lets', 3267),\n ('ve', 3263),\n ('vlogs', 3258),\n ('light', 3254),\n ('hands', 3247),\n ('knows', 3242),\n ('become', 3242),\n ('ride', 3238),\n ('30', 3238),\n ('killed', 3236),\n ('tail', 3228),\n ('feeding', 3217),\n ('15', 3214),\n ('open', 3208),\n ('birds', 3203),\n ('raptor', 3197),\n ('less', 3191),\n ('liked', 3191),\n ('giving', 3187),\n ('body', 3183),\n ('bought', 3177),\n ('etc', 3171),\n ('helping', 3158),\n ('fast', 3150),\n ('chance', 3139),\n ('yay', 3127),\n ('strong', 3124),\n ('matter', 3121),\n ('treat', 3119),\n ('lmao', 3112),\n ('wtf', 3102),\n ('game', 3090),\n ('havent', 3087),\n ('gecko', 3079),\n ('bunny', 3077),\n ('green', 3074),\n ('dream', 3066),\n ('inside', 3058),\n ('owners', 3052),\n ('dragon', 3052),\n ('fact', 3048),\n ('fox', 3046),\n ('weird', 3042),\n ('rabbit', 3037),\n ('yellow', 3036),\n ('forward', 3021),\n ('death', 3019),\n ('send', 3001),\n ('fight', 2993),\n ('tho', 2986),\n ('smart', 2986),\n ('gorgeous', 2980),\n ('tree', 2975),\n ('gone', 2974),\n ('vs', 2971),\n ('jesus', 2965),\n ('hold', 2952),\n ('para', 2952),\n ('special', 2943),\n ('waiting', 2937),\n ('course', 2937),\n ('smile', 2934),\n ('reptile', 2930),\n ('near', 2930),\n ('honestly', 2919),\n ('pit', 2917),\n ('playing', 2909),\n ('youve', 2896),\n ('support', 2895),\n ('una', 2891),\n ('size', 2888),\n ('abuse', 2888),\n ('training', 2883),\n ('imagine', 2883),\n ('bone', 2882),\n ('forever', 2882),\n ('sting', 2880),\n ('bigger', 2878),\n ('species', 2875),\n ('nature', 2865),\n ('voice', 2860),\n ('experience', 2857),\n ('clean', 2844),\n ('meet', 2841),\n ('sleep', 2838),\n ('saving', 2832),\n ('sea', 2831),\n ('content', 2822),\n ('mouth', 2820),\n ('www', 2815),\n ('subscribed', 2813),\n ('sooo', 2813),\n ('working', 2808),\n ('future', 2802),\n ('saved', 2784),\n ('precious', 2776),\n ('helped', 2771),\n ('50', 2771),\n ('giant', 2762),\n ('healthy', 2753),\n ('along', 2749),\n ('creatures', 2747),\n ('turn', 2736),\n ('pls', 2734),\n ('child', 2730),\n ('lady', 2728),\n ('running', 2727),\n ('lizard', 2718),\n ('normal', 2717),\n ('easy', 2707),\n ('woman', 2705),\n ('truly', 2697),\n ('legs', 2686),\n ('feeling', 2679),\n ('anymore', 2676),\n ('german', 2671),\n ('blood', 2667),\n ('behind', 2665),\n ('bee', 2660),\n ('possible', 2658),\n ('eggs', 2655),\n ('often', 2651),\n ('country', 2648),\n ('rip', 2648),\n ('bet', 2648),\n ('kept', 2646),\n ('shows', 2644),\n ('post', 2640),\n ('hay', 2639),\n ('hours', 2636),\n ('sister', 2627),\n ('missed', 2618),\n ('13', 2612),\n ('king', 2611),\n ('cutest', 2599),\n ('fake', 2597),\n ('14', 2591),\n ('add', 2583),\n ('dangerous', 2582),\n ('ha', 2578),\n ('bed', 2570),\n ('area', 2560),\n ('team', 2555),\n ('past', 2550),\n ('usually', 2548),\n ('minutes', 2546),\n ('spiders', 2544),\n ('share', 2543),\n ('stacy', 2542),\n ('bitten', 2538),\n ('frog', 2537),\n ('shelby', 2537),\n ('quite', 2530),\n ('age', 2525),\n ('sub', 2512),\n ('buddy', 2509),\n ('children', 2501),\n ('earth', 2500),\n ('abi', 2500),\n ('adopted', 2491),\n ('pero', 2490),\n ('anyway', 2485),\n ('opinion', 2481),\n ('sell', 2481),\n ('everyday', 2475),\n ('seriously', 2475),\n ('mad', 2474),\n ('tiny', 2473),\n ('appreciate', 2473),\n ('exactly', 2473),\n ('happens', 2470),\n ('como', 2467),\n ('wasp', 2466),\n ('re', 2465),\n ('means', 2463),\n ('cuz', 2462),\n ('leg', 2461),\n ('cried', 2460),\n ('older', 2451),\n ('loki', 2451),\n ('train', 2440),\n ('horrible', 2426),\n ('views', 2420),\n ('al', 2414),\n ('feels', 2413),\n ('gallon', 2400),\n ('riding', 2396),\n ('keeping', 2395),\n ('needed', 2394),\n ('surgery', 2391),\n ('attack', 2385),\n ('self', 2383),\n ('subscribe', 2376),\n ('break', 2370),\n ('durian', 2364),\n ('takes', 2363),\n ('laugh', 2362),\n ('caught', 2361),\n ('pay', 2359),\n ('yall', 2357),\n ('season', 2355),\n ('tanks', 2354),\n ('hot', 2354),\n ('_', 2352),\n ('trust', 2351),\n ('afraid', 2351),\n ('completely', 2347),\n ('handle', 2346),\n ('congratulations', 2343),\n ('front', 2343),\n ('movie', 2342),\n ('word', 2341),\n ('attention', 2339),\n ('bag', 2335),\n ('touch', 2332),\n ('teach', 2330),\n ('fear', 2326),\n ('alot', 2325),\n ('number', 2322),\n ('steve', 2320),\n ('subs', 2319),\n ('felt', 2315),\n ('gotta', 2310),\n ('won', 2307),\n ('tv', 2304),\n ('chicken', 2294),\n ('color', 2292),\n ('girls', 2285),\n ('australia', 2284),\n ('shot', 2283),\n ('showing', 2283),\n ('toby', 2281),\n ('rick', 2280),\n ('feet', 2279),\n ('alive', 2276),\n ('link', 2272),\n ('bear', 2271),\n ('bitch', 2267),\n ('reminds', 2248),\n ('muy', 2244),\n ('ready', 2241),\n ('short', 2238),\n ('wiggle', 2236),\n ('info', 2233),\n ('q', 2227),\n ('fur', 2225),\n ('del', 2224),\n ('40', 2223),\n ('rock', 2222),\n ('plus', 2222),\n ('soo', 2220),\n ('large', 2215),\n ('bull', 2206),\n ('works', 2205),\n ('passed', 2202),\n ('title', 2197),\n ('lori', 2196),\n ('taken', 2195),\n ('single', 2193),\n ('fire', 2192),\n ('cruel', 2189),\n ('hopefully', 2189),\n ('jump', 2187),\n ('sense', 2183),\n ('rescued', 2182),\n ('nope', 2181),\n ('case', 2174),\n ('00', 2170),\n ('moment', 2170),\n ('stand', 2166),\n ('learned', 2158),\n ('challenge', 2155),\n ('recently', 2154),\n ('idk', 2144),\n ('fruit', 2142),\n ('men', 2139),\n ('worse', 2139),\n ('whatever', 2133),\n ('thumbs', 2127),\n ('f', 2126),\n ('sylvester', 2124),\n ('listen', 2115),\n ('18', 2114),\n ('late', 2113),\n ('shirt', 2111),\n ('beat', 2109),\n ('meat', 2108),\n ('pray', 2107),\n ('rather', 2106),\n ('million', 2098),\n ('adventure', 2095),\n ('thinks', 2095),\n ('click', 2089),\n ('ears', 2079),\n ('pig', 2077),\n ('cancer', 2076),\n ('words', 2074),\n ('honey', 2065),\n ('soooo', 2064),\n ('advice', 2059),\n ('te', 2058),\n ('bearded', 2055),\n ('pitbull', 2053),\n ('le', 2051),\n ('brain', 2051),\n ('putting', 2049),\n ('da', 2045),\n ('las', 2043),\n ('dr', 2041),\n ('mix', 2041),\n ('wife', 2040),\n ('door', 2039),\n ('dislike', 2039),\n ('skin', 2038),\n ('fat', 2034),\n ('wolf', 2033),\n ('however', 2028),\n ('worth', 2026),\n ('treats', 2019),\n ('worst', 2018),\n ('longer', 2016),\n ('cold', 2011),\n ('shouldnt', 2008),\n ('angel', 2005),\n ('holy', 2002),\n ('peace', 1998),\n ('snow', 1994),\n ('leopard', 1994),\n ('problems', 1992),\n ('lived', 1990),\n ('sit', 1989),\n ('lord', 1986),\n ('bees', 1984),\n ('due', 1982),\n ('dan', 1979),\n ('turned', 1978),\n ('stick', 1977),\n ('bites', 1976),\n ('favourite', 1976),\n ('youtuber', 1975),\n ('breeding', 1965),\n ('youll', 1961),\n ('brought', 1954),\n ('balls', 1954),\n ('beginning', 1952),\n ('natural', 1946),\n ('cho', 1944),\n ('16', 1941),\n ('random', 1939),\n ('inspired', 1937),\n ('sand', 1936),\n ('reaction', 1935),\n ('lion', 1934),\n ('fantastic', 1933),\n ('road', 1929),\n ('lil', 1927),\n ('clip', 1916),\n ('dear', 1914),\n ('viktor', 1914),\n ('phone', 1909),\n ('gives', 1908),\n ('yesterday', 1906),\n ('follow', 1900),\n ('hahaha', 1898),\n ('walking', 1897),\n ('kitties', 1897),\n ('given', 1895),\n ('obviously', 1894),\n ('crab', 1892),\n ('american', 1892),\n ('freaking', 1885),\n ('visit', 1884),\n ('ate', 1884),\n ('tips', 1883),\n ('similar', 1881),\n ('positive', 1879),\n ('interested', 1876),\n ('worry', 1875),\n ('ranch', 1874),\n ('research', 1873),\n ('pup', 1871),\n ('names', 1870),\n ('foot', 1868),\n ('power', 1868),\n ('important', 1866),\n ('trending', 1865),\n ('ground', 1864),\n ('enter', 1860),\n ('information', 1858),\n ('fall', 1854),\n ('english', 1853),\n ('soul', 1852),\n ('thor', 1852),\n ('noticed', 1852),\n ('throw', 1850),\n ('enjoyed', 1848),\n ('space', 1846),\n ('broke', 1842),\n ('ko', 1839),\n ('rats', 1837),\n ('daughter', 1836),\n ('17', 1836),\n ('ant', 1830),\n ('hedgehog', 1828),\n ('deal', 1828),\n ('step', 1827),\n ('fell', 1824),\n ('trained', 1817),\n ('situation', 1811),\n ('laughing', 1811),\n ('evil', 1810),\n ('tears', 1807),\n ('mario', 1806),\n ('quality', 1802),\n ('reading', 1799),\n ('learning', 1799),\n ('series', 1798),\n ('starting', 1797),\n ('shelter', 1796),\n ('w', 1794),\n ('curious', 1793),\n ('meow', 1793),\n ('su', 1791),\n ('toys', 1781),\n ('clickbait', 1781),\n ('arm', 1780),\n ('biggest', 1778),\n ('crap', 1771),\n ('scary', 1769),\n ('list', 1768),\n ('calm', 1767),\n ('aquarium', 1765),\n ('http', 1762),\n ('born', 1762),\n ('shrimp', 1755),\n ('piece', 1755),\n ('plants', 1753),\n ('notice', 1752),\n ('adventures', 1750),\n ('awwww', 1748),\n ('killing', 1747),\n ('goldfish', 1746),\n ('women', 1745),\n ('heaven', 1743),\n ('nose', 1743),\n ('disgusting', 1740),\n ('subscribers', 1739),\n ('rat', 1739),\n ('toy', 1737),\n ('merry', 1735),\n ('paws', 1733),\n ('moving', 1730),\n ('ran', 1729),\n ('ku', 1728),\n ('betta', 1728),\n ('zone', 1726),\n ('across', 1724),\n ('tu', 1722),\n ('spot', 1720),\n ('line', 1713),\n ('unless', 1712),\n ('continue', 1711),\n ('orange', 1709),\n ('helps', 1708),\n ('places', 1707),\n ('thumbnail', 1706),\n ('friendly', 1706),\n ('pop', 1705),\n ('dumb', 1705),\n ('showed', 1703),\n ('health', 1702),\n ('father', 1702),\n ('25', 1699),\n ('uk', 1699),\n ('fly', 1696),\n ('state', 1689),\n ('zoo', 1689),\n ('gosh', 1687),\n ('picture', 1687),\n ('forget', 1686),\n ('teeth', 1684),\n ('statue', 1683),\n ('boys', 1678),\n ('whos', 1678),\n ('broken', 1676),\n ('spend', 1673),\n ('2017', 1671),\n ('entire', 1670),\n ('except', 1668),\n ('asked', 1668),\n ('deserves', 1666),\n ...]"
     ]
    }
   ],
   "source": [
    "wcSorted = sorted(wc.items(), key=lambda kv: kv[1],reverse = True)\n",
    "wcSorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d21b7073-be88-4faa-a9de-08188de34249",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-4295172853616343>:10\u001B[0m\n",
       "\u001B[1;32m      6\u001B[0m wcloud \u001B[38;5;241m=\u001B[39m WordCloud(background_color\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwhite\u001B[39m\u001B[38;5;124m\"\u001B[39m, max_words\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m20000\u001B[39m, collocations\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n",
       "\u001B[1;32m      7\u001B[0m                    contour_width\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m, contour_color\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msteelblue\u001B[39m\u001B[38;5;124m'\u001B[39m, max_font_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m40\u001B[39m)\n",
       "\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m# Generate a word cloud image\u001B[39;00m\n",
       "\u001B[0;32m---> 10\u001B[0m wcloud\u001B[38;5;241m.\u001B[39mgenerate(text)\n",
       "\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m# Display the generated image:\u001B[39;00m\n",
       "\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# the matplotlib way:\u001B[39;00m\n",
       "\u001B[1;32m     14\u001B[0m fig,ax0\u001B[38;5;241m=\u001B[39mplt\u001B[38;5;241m.\u001B[39msubplots(nrows\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m12\u001B[39m,\u001B[38;5;241m8\u001B[39m))\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-c79cae24-17e1-486e-8d44-77a231fe52b6/lib/python3.9/site-packages/wordcloud/wordcloud.py:642\u001B[0m, in \u001B[0;36mWordCloud.generate\u001B[0;34m(self, text)\u001B[0m\n",
       "\u001B[1;32m    627\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgenerate\u001B[39m(\u001B[38;5;28mself\u001B[39m, text):\n",
       "\u001B[1;32m    628\u001B[0m     \u001B[38;5;124;03m\"\"\"Generate wordcloud from text.\u001B[39;00m\n",
       "\u001B[1;32m    629\u001B[0m \n",
       "\u001B[1;32m    630\u001B[0m \u001B[38;5;124;03m    The input \"text\" is expected to be a natural text. If you pass a sorted\u001B[39;00m\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m    640\u001B[0m \u001B[38;5;124;03m    self\u001B[39;00m\n",
       "\u001B[1;32m    641\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
       "\u001B[0;32m--> 642\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate_from_text\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-c79cae24-17e1-486e-8d44-77a231fe52b6/lib/python3.9/site-packages/wordcloud/wordcloud.py:624\u001B[0m, in \u001B[0;36mWordCloud.generate_from_text\u001B[0;34m(self, text)\u001B[0m\n",
       "\u001B[1;32m    607\u001B[0m \u001B[38;5;124;03m\"\"\"Generate wordcloud from text.\u001B[39;00m\n",
       "\u001B[1;32m    608\u001B[0m \n",
       "\u001B[1;32m    609\u001B[0m \u001B[38;5;124;03mThe input \"text\" is expected to be a natural text. If you pass a sorted\u001B[39;00m\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m    621\u001B[0m \u001B[38;5;124;03mself\u001B[39;00m\n",
       "\u001B[1;32m    622\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n",
       "\u001B[1;32m    623\u001B[0m words \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_text(text)\n",
       "\u001B[0;32m--> 624\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate_from_frequencies\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwords\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    625\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-c79cae24-17e1-486e-8d44-77a231fe52b6/lib/python3.9/site-packages/wordcloud/wordcloud.py:511\u001B[0m, in \u001B[0;36mWordCloud.generate_from_frequencies\u001B[0;34m(self, frequencies, max_font_size)\u001B[0m\n",
       "\u001B[1;32m    508\u001B[0m transposed_font \u001B[38;5;241m=\u001B[39m ImageFont\u001B[38;5;241m.\u001B[39mTransposedFont(\n",
       "\u001B[1;32m    509\u001B[0m     font, orientation\u001B[38;5;241m=\u001B[39morientation)\n",
       "\u001B[1;32m    510\u001B[0m \u001B[38;5;66;03m# get size of resulting text\u001B[39;00m\n",
       "\u001B[0;32m--> 511\u001B[0m box_size \u001B[38;5;241m=\u001B[39m \u001B[43mdraw\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtextbbox\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mword\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfont\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtransposed_font\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43manchor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    512\u001B[0m \u001B[38;5;66;03m# find possible places using integral image:\u001B[39;00m\n",
       "\u001B[1;32m    513\u001B[0m result \u001B[38;5;241m=\u001B[39m occupancy\u001B[38;5;241m.\u001B[39msample_position(box_size[\u001B[38;5;241m3\u001B[39m] \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmargin,\n",
       "\u001B[1;32m    514\u001B[0m                                    box_size[\u001B[38;5;241m2\u001B[39m] \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmargin,\n",
       "\u001B[1;32m    515\u001B[0m                                    random_state)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.9/site-packages/PIL/ImageDraw.py:671\u001B[0m, in \u001B[0;36mImageDraw.textbbox\u001B[0;34m(self, xy, text, font, anchor, spacing, align, direction, features, language, stroke_width, embedded_color)\u001B[0m\n",
       "\u001B[1;32m    669\u001B[0m     font \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgetfont()\n",
       "\u001B[1;32m    670\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(font, ImageFont\u001B[38;5;241m.\u001B[39mFreeTypeFont):\n",
       "\u001B[0;32m--> 671\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOnly supported for TrueType fonts\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m    672\u001B[0m mode \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRGBA\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m embedded_color \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfontmode\n",
       "\u001B[1;32m    673\u001B[0m bbox \u001B[38;5;241m=\u001B[39m font\u001B[38;5;241m.\u001B[39mgetbbox(\n",
       "\u001B[1;32m    674\u001B[0m     text, mode, direction, features, language, stroke_width, anchor\n",
       "\u001B[1;32m    675\u001B[0m )\n",
       "\n",
       "\u001B[0;31mValueError\u001B[0m: Only supported for TrueType fonts"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)\nFile \u001B[0;32m<command-4295172853616343>:10\u001B[0m\n\u001B[1;32m      6\u001B[0m wcloud \u001B[38;5;241m=\u001B[39m WordCloud(background_color\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwhite\u001B[39m\u001B[38;5;124m\"\u001B[39m, max_words\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m20000\u001B[39m, collocations\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m      7\u001B[0m                    contour_width\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m, contour_color\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msteelblue\u001B[39m\u001B[38;5;124m'\u001B[39m, max_font_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m40\u001B[39m)\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m# Generate a word cloud image\u001B[39;00m\n\u001B[0;32m---> 10\u001B[0m wcloud\u001B[38;5;241m.\u001B[39mgenerate(text)\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m# Display the generated image:\u001B[39;00m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# the matplotlib way:\u001B[39;00m\n\u001B[1;32m     14\u001B[0m fig,ax0\u001B[38;5;241m=\u001B[39mplt\u001B[38;5;241m.\u001B[39msubplots(nrows\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m12\u001B[39m,\u001B[38;5;241m8\u001B[39m))\n\nFile \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-c79cae24-17e1-486e-8d44-77a231fe52b6/lib/python3.9/site-packages/wordcloud/wordcloud.py:642\u001B[0m, in \u001B[0;36mWordCloud.generate\u001B[0;34m(self, text)\u001B[0m\n\u001B[1;32m    627\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgenerate\u001B[39m(\u001B[38;5;28mself\u001B[39m, text):\n\u001B[1;32m    628\u001B[0m     \u001B[38;5;124;03m\"\"\"Generate wordcloud from text.\u001B[39;00m\n\u001B[1;32m    629\u001B[0m \n\u001B[1;32m    630\u001B[0m \u001B[38;5;124;03m    The input \"text\" is expected to be a natural text. If you pass a sorted\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    640\u001B[0m \u001B[38;5;124;03m    self\u001B[39;00m\n\u001B[1;32m    641\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 642\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate_from_text\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-c79cae24-17e1-486e-8d44-77a231fe52b6/lib/python3.9/site-packages/wordcloud/wordcloud.py:624\u001B[0m, in \u001B[0;36mWordCloud.generate_from_text\u001B[0;34m(self, text)\u001B[0m\n\u001B[1;32m    607\u001B[0m \u001B[38;5;124;03m\"\"\"Generate wordcloud from text.\u001B[39;00m\n\u001B[1;32m    608\u001B[0m \n\u001B[1;32m    609\u001B[0m \u001B[38;5;124;03mThe input \"text\" is expected to be a natural text. If you pass a sorted\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    621\u001B[0m \u001B[38;5;124;03mself\u001B[39;00m\n\u001B[1;32m    622\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    623\u001B[0m words \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_text(text)\n\u001B[0;32m--> 624\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate_from_frequencies\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwords\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    625\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n\nFile \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-c79cae24-17e1-486e-8d44-77a231fe52b6/lib/python3.9/site-packages/wordcloud/wordcloud.py:511\u001B[0m, in \u001B[0;36mWordCloud.generate_from_frequencies\u001B[0;34m(self, frequencies, max_font_size)\u001B[0m\n\u001B[1;32m    508\u001B[0m transposed_font \u001B[38;5;241m=\u001B[39m ImageFont\u001B[38;5;241m.\u001B[39mTransposedFont(\n\u001B[1;32m    509\u001B[0m     font, orientation\u001B[38;5;241m=\u001B[39morientation)\n\u001B[1;32m    510\u001B[0m \u001B[38;5;66;03m# get size of resulting text\u001B[39;00m\n\u001B[0;32m--> 511\u001B[0m box_size \u001B[38;5;241m=\u001B[39m \u001B[43mdraw\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtextbbox\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mword\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfont\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtransposed_font\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43manchor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    512\u001B[0m \u001B[38;5;66;03m# find possible places using integral image:\u001B[39;00m\n\u001B[1;32m    513\u001B[0m result \u001B[38;5;241m=\u001B[39m occupancy\u001B[38;5;241m.\u001B[39msample_position(box_size[\u001B[38;5;241m3\u001B[39m] \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmargin,\n\u001B[1;32m    514\u001B[0m                                    box_size[\u001B[38;5;241m2\u001B[39m] \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmargin,\n\u001B[1;32m    515\u001B[0m                                    random_state)\n\nFile \u001B[0;32m/databricks/python/lib/python3.9/site-packages/PIL/ImageDraw.py:671\u001B[0m, in \u001B[0;36mImageDraw.textbbox\u001B[0;34m(self, xy, text, font, anchor, spacing, align, direction, features, language, stroke_width, embedded_color)\u001B[0m\n\u001B[1;32m    669\u001B[0m     font \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgetfont()\n\u001B[1;32m    670\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(font, ImageFont\u001B[38;5;241m.\u001B[39mFreeTypeFont):\n\u001B[0;32m--> 671\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOnly supported for TrueType fonts\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    672\u001B[0m mode \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRGBA\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m embedded_color \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfontmode\n\u001B[1;32m    673\u001B[0m bbox \u001B[38;5;241m=\u001B[39m font\u001B[38;5;241m.\u001B[39mgetbbox(\n\u001B[1;32m    674\u001B[0m     text, mode, direction, features, language, stroke_width, anchor\n\u001B[1;32m    675\u001B[0m )\n\n\u001B[0;31mValueError\u001B[0m: Only supported for TrueType fonts",
       "errorSummary": "<span class='ansi-red-fg'>ValueError</span>: Only supported for TrueType fonts",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text = \" \".join([(k + \" \")*v for k, v in wc.items()])\n",
    "\n",
    "wcloud = WordCloud(background_color=\"white\", max_words=20000, collocations=False,\n",
    "                   contour_width=3, contour_color='steelblue', max_font_size=40)\n",
    "\n",
    "# Generate a word cloud image\n",
    "wcloud.generate(text)\n",
    "\n",
    "# Display the generated image:\n",
    "# the matplotlib way:\n",
    "fig,ax0=plt.subplots(nrows=1,figsize=(12,8))\n",
    "ax0.imshow(wcloud,interpolation='bilinear')\n",
    "\n",
    "ax0.axis(\"off\")\n",
    "display(fig)\n",
    "\n",
    "## not a lot of obvious features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9e5656c-fa5d-430c-85f9-a4deda225166",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 5. Identify Creators With Cat And Dog Owners In The Audience\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b986d0a-a818-4d3c-9477-91b74c224a54",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+------+\n|           creator_name|  name|\n+-----------------------+------+\n|       Brave Wilderness|198449|\n|          Brian Barczyk| 75912|\n|               The Dodo| 70884|\n|     Taylor Nicole Dean| 50480|\n|   Hope For Paws - O...| 27141|\n|           Robin Seplut| 25595|\n|              Vet Ranch| 22350|\n|            Info Marvel| 20960|\n|        Gohan The Husky| 20838|\n|               ViralHog| 18274|\n|Íº¨Î∂ÄÍ∏∞ÏïÑÎπ† My Pet Diary| 17658|\n|        Viktor Larkhill| 17459|\n|      Talking Kitty Cat| 14667|\n|              MonkeyBoo| 13827|\n|    Keedes channel LIVE| 12570|\n|     Think Like A Horse| 11953|\n|   Gone to the Snow ...| 11523|\n|               M·∫°nh CFM| 11272|\n|       Cole & Marmalade| 10640|\n|           Mr. Max T.V.| 10485|\n+-----------------------+------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "#Get all creators whenever the users label is True(cat/dog owner)\n",
    "df_create = dataset.select('creator_name').union(pred_all.filter(F.col('prediction') == 1.0).select('creator_name'))\n",
    "\n",
    "df_create.createOrReplaceTempView(\"create_table\")\n",
    "\n",
    "#get count\n",
    "create_count = spark.sql(\"select distinct creator_name, count(*) as name\\\n",
    "                          from create_table \\\n",
    "                          group by creator_name \\\n",
    "                          order by name DESC\")\n",
    "\n",
    "create_count.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71004a90-2b86-4e4e-803a-cb81ed5f0cb3",
     "showTitle": true,
     "title": "Prepare a technical report here"
    }
   },
   "source": [
    "#### 6. Analysis and Future work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7470910c-c24b-4d18-b988-e3fa6178db3c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "Only part of the dataset was used due to the lack of computation power for the entire dataset, which could be the reason that output features and topics do not seem to be much related. Also, model fine tuning can be done to improve the model performances, which could also help with getting better results.\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3577094307044609,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "YouTube Comment",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
